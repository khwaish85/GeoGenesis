{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üß™ Soil Image Classification Challenge - Google Colab Notebook\n",
    "\n",
    "## üì¶ Step 1: Upload Dataset (zip file)\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "with zipfile.ZipFile(\"soil_classification-2025.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n",
    "\n",
    "print(\"Extracted files:\")\n",
    "print(os.listdir(\"soil_classification-2025\"))\n",
    "\n",
    "## üß∞ Step 2: Install Required Libraries\n",
    "!pip install -q efficientnet_pytorch scikit-learn\n",
    "\n",
    "## ‚öôÔ∏è Step 3: Import Libraries\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n",
    "\n",
    "## üìÅ Step 4: Set Paths (Updated for your ZIP structure)\n",
    "train_csv = 'soil_classification-2025/train_labels.csv'\n",
    "train_dir = 'soil_classification-2025/train'\n",
    "test_dir = 'soil_classification-2025/test'\n",
    "submission_file = 'soil_classification-2025/test_ids.csv'\n",
    "\n",
    "## ‚öôÔ∏è Step 5: Define Constants and Helpers\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "SEED = 42\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "label2idx = {'Alluvial soil': 0, 'Black Soil': 1, 'Clay soil': 2, 'Red soil': 3}\n",
    "idx2label = {v: k for k, v in label2idx.items()}\n",
    "\n",
    "class SoilDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, train=True):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(os.path.join(self.img_dir, row['image_id'])).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.train:\n",
    "            label = label2idx[row['soil_type']]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, row['image_id']\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def get_model():\n",
    "    model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=4)\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "def train_one_fold(model, train_loader, val_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    best_f1 = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.numpy())\n",
    "\n",
    "        scores = [f1_score(val_labels, val_preds, labels=[i], average='macro') for i in range(4)]\n",
    "        min_f1 = min(scores)\n",
    "        print(f\"Min F1-score: {min_f1:.4f}, All: {np.round(scores, 4)}\")\n",
    "\n",
    "        if min_f1 > best_f1:\n",
    "            best_f1 = min_f1\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    print(f\"Best Min F1-score: {best_f1:.4f}\")\n",
    "\n",
    "## üß† Step 6: Train Model\n",
    "df = pd.read_csv(train_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, stratify=df['soil_type'], test_size=0.2, random_state=SEED)\n",
    "\n",
    "train_ds = SoilDataset(train_df, train_dir, train_transforms)\n",
    "val_ds = SoilDataset(val_df, train_dir, test_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = get_model()\n",
    "train_one_fold(model, train_loader, val_loader)\n",
    "\n",
    "## üîç Step 7: Inference and Submission\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_df = pd.read_csv(submission_file)\n",
    "test_ds = SoilDataset(test_df, test_dir, test_transforms, train=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "all_preds, all_ids = [], []\n",
    "with torch.no_grad():\n",
    "    for images, image_ids in tqdm(test_loader, desc=\"Inference\"):\n",
    "        images = images.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_ids.extend(image_ids)\n",
    "\n",
    "submission = pd.DataFrame({'image_id': all_ids, 'soil_type': [idx2label[p] for p in all_preds]})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Saved submission.csv\")\n",
    "\n",
    "## üì§ Step 8: Download Submission\n",
    "from google.colab import files\n",
    "files.download('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
